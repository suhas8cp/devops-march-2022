Docker 
	Docker is one of the tools that used the idea of the isolated resources to 
	create a container that allows applications to be packaged with all the 
	dependencies installed and ran wherever we wanted.
	
	Docker can only run on Linux machines this means I cant install Dokcer directly on Windows or any other OS.
	If I want install Docker on windows then I need to run a Linux VM in windows on top that I need to run Docker.

Virtualization (VM)
	- VM is way of running virtual OS on top a host OS using a special software called Hyperviser.
	- VM directly shares the harware of the host OS. 

					VM 					vs 			Containerisation 
	1. Virtualization at hardware level  		1. Virtualization at OS level 
	2. Heavyweight - consume more host 			2. Lightweight
	   resources 	
	3. VM useses hypervisor 					3. containerisation tool is used 
	4. limited performace - Boot up time        4. Native performace - usualy boot 
		is more which is in minutes 			   fast in seconds.
	5. Cosumes more storage 					5. Shres OS storage means only uses 
												   required storage.
	6. Supports all OS 							6. Supports on Linux

host machine 
	This is the machine in which docker is running 
	
Docker image 

	To list images 
		docker images
		
	To download images from docker hub 
		docker pull <image_name>:<tag>

		note: The default tag will be always latest.
			  if we wont specify any tag latest will be considered 	
			  
	To connect to your docker hub account 
		docker login 

	To pull a image from your repo 
		docoker pull <username>/<image_name>:<tag>	
		
		ex: docker pull harshajain/my_ubuntu
		
	To push a image to your repo 

		1. Create a tag which matches your repo syntax 
			docker tag <old_name> <new_name>
			
			ex: docker tag ubuntu:22.10 harshajain/test:1.0
		
		2. Push the image 	
			docoker push <username>/<image_name>:<tag>	
		
			ex: docker push harshajain/test:1.0	
		
Docker container 
	A container is a set of isolated processes and resources. Linux achieves 
	this by using namespaces, which allows processes to access only resources 
	in that particular namespace, which allows having a process tree means set 
	of processes that is completely independent of the rest of the systems processes.
	
	Docker definition: A container is a standard unit of software that packages 
	up code and all its dependencies so the application runs quickly and reliably 
	from one computing environment to another.
	
	To list running containers 
		docker ps 
			(or)
		docker container ls 
	
	To list all containers
		docker ps -a 
	
	To list all stopped conatainers
		docker ps -a --filter status=exited
		
	To delete one or more container 	
		docker rm <conainter_id1> <conainter_id2> .... 
		
		To delete a running container 
			1. Forcefully - docker rm -f <conainter_id>
			2. Grace fully - docker rm $(docker stop <conainter_id>) 
											(or)
							 docker stop <conainter_id> | xargs -I{} docker rm "{}"						
				
	To delete all stopped/exited containers 
		docker rm $(docker ps -aq --filter status=exited)	
					(or)
		docker container prune
		
	To run a command inside a conatainer 
		docker exec -it <container_id> <command>
		
	To check the logs of conatainers 
		docker logs <container_id>

	To login / get inside a containre 
		docker attach <container_ID>  
				(safe exit <ctrl>+qp)
					(OR)
		docker exec -it <container_ID> /bin/bash		
	
	To create a container from a docker image 
		docker run -it -d --name <conainter_name> <image>:<tag> <run_time_command>
		
		-it - Interactive Terminal (tty) 
		-d - deatached mode (when ever we create a container it will auto login to avoid this 
			we can create a container in detached mode)
		--name used to provide user defined conatainer name
		
		Note: Always use the options before <image>:<tag> <run_time_command>
		
		ex: docker run -it -d --name my_jenkins -p 8080:8080 -p 50000:50000 jenkins/jenkins
		
Assignment: work with docker image and container commands
			Try to create a jenkins container (jenkins/jenkins:lts)		
	
	docker commit 
	docker export 
	docker import 
	docker save 
	
Docker custom image / Dockerfile
	Dockerfile
		Dockerfile is used to create custom images by using any stock image or other image as base image.
		In Dockerfile we can write some set of instructions to update any image.
	
		To create image from Dockerfile
			docker build -t my_ubuntu .
	
	FROM ubuntu
		FROM is the first instruction in the every Dockerfile
		FROM is used to specify the base image on top which all the other 
			instruction will run in the same Dockerfile.
			
		FROM <image_name>:<tag>
		
	RUN 
		Normal shell command or the commands supported by the base image are executed using this instruction.
		we can have n number of RUN in a single Dockerfile.
		
		Normal command format 
			RUN <command>
			
		exec format 
			RUN ['<command>','<param1>','<param2>']	
			RUN ['apt','update']	
			RUN ['apt','install','-y','git']	
			RUN ['ls','-lrt']	 
			
	ENV 
		- This instruction is used to set the environment variable inside the container.
		
		ENV <variable_name> <value>
		ENV <variable_name>=<value>
		
		multiple 
		ENV <variable_name>=<value> <variable_name>=<value> <variable_name>=<value> ....
		
		To create environment variables at run time 
			- using -e or --env option at the runtime we can create env variables 
			- For multiple variables use multiple -e 

		ex:	docker run .... -e <variable_name>=<value> -e <variable_name>=<value> ....	
		
		The best way to load multiple env variable is using env file 
			using --env-file <file_path> at the runtime (with docker run command) we can 
			load the env file containing n number variables. 
	
	ARG
		Using ARG we can pass parameters to Dockerfile as user inputs 
			
		ARG <var_name>=<default_value>

		To pass the value at build time 
			docker build --build-arg <var_name>=<value> ....	
		
	COPY and ADD 
		- Both copy and add instruction is used to copy files and directories from host machine to the image.
		- The source path to copy files should always be evaluted with reference to Dockerfile.
		
		ADD supports extra source formats 
			- If the source is a compressed file add will automatically 
			  uncompresses it to the destination.
			- If the source is a link to a downloadable file it will download 
			  to the destination.
			  
		COPY <source_path_from_build_context> <destination_inside_image>	  
		ADD <source_path_from_build_context> <destination_inside_image>	  
		
		
	CMD and ENTRYPOINT
		shell format 
			CMD "ls -lrt"
			ENTRYPOINT "ls -lrt"
			
		EXEC Format
			CMD ["ls","-l","-rt"]
			ENTRYPOINT ["ls","-lrt"]
			
		- Both CMD and ENTRYPOINT are used to define the execution command of the container which will be created 
		  from this image.
		- If we use multiple CMD or ENTRYPOINT in the same Dockerfile only the latest one will be considered 
		  and all the other CMD or ENTRYPOINT will be ignored.	
		- If we use both CMD and ENTRYPOINT in the same Dockerfile, ENTRYPOINT will get the 
		  higest priority and the command of CMD will become as argumetns to ENTRYPOINT	
		  
		 Difference  
		  -	CMD command can be overridden at the runtime.	
		  - ENTRYPOINT can't be overridden at the runtime but the runtime command
		    will become parameters to ENTRYPOINT command.
		  
		Note: Q. Can we override ENTRYPOINT 
				 Yes, after docker 1.6 version docker has given option to over
					  Entrypoint command at the runtime using --entrypoint 
	
	EXPOSE 
		EXPOSE <port_number>
		- Used to expose a port to the docker network 
		- This is make the  port accessable by all the other containers in the 
		  same docker network.	

	WORKDIR
		This is used to set the working directory for all the instructions that follows it
		such as RUN, CMD, ENTRYPOINT, COPY, ADD
		
		WORKDIR <path>
		
Docker Volumes
 	- As the layers inside the image are readonly which means once the image is created 
	  we cannot change/edit so we cannot put the conatainer data in image.
	- Container create a top most RW layer and all the runtime data is saved here. 
	- Container layer is temparary layer, If we loose the container we loose data. so
	  to retain/persist the container runtime data we need docker volumes.

	Bind Mounts 
		- we can mount host machine filesystem (files and directories) to the container
		
			docker run -v <host_path>:<container_path>
	
	Docker Volumes		
		- These are docker managed filesystem and we use docker commands to manage these
		  volumes 
		- Volumes are easier to manage, backup or migrate than bind mounts.
		- Volumes supports many drivers which means we can maunt many types of filesystem.
		- Default location of docker volume is /var/lib/docker/volumes  	
		
		docker run -v <volume_name>:<container_path>
		
		To create volume 
			docker volume create <volume_name>
			
		To list volume 
			docker volume ls	
			
		To Delete volume 
			docker volume rm <volume_name>
			
Namespaces and cgroups
	- Docker uses linux namespaces to provide isolated workspace for processes called
	  conatainer
	- when a container is created, docker creates a set of namespaces for it and provides 
	  a layer of isolation for container.
	- Each container run in a different namespace 
	
	namespace (To list - lsns)
		cgroups 
			- Linux OS uses cgroups to manage the availale hardware resoruces such as 
			  cpu, RAM, Disk, I/O.
			- we can control tje access and also we can apply the limitations 

			To list - lscgroup	
		pid - namespace for managing processes (process isolation)
		user - namespace for non-root user on linux.
		uts - namespace for unix timesharing system which isolates kernel and version identifiers,
			  time bonding of process.
		ipc - (interprocess communication) namespace for managing the process communication.	  
		mnt - namespace for managing filesystem mounts.
		net - namespace for managing network interfaces.
		
Docker networking 
	Publish 
		PUBLISH = Expose + outside world port mapping 
			
	- publics will bind the container port to the host port which we can access from 
	  outside world using <host_ip>:<port_mapped>
	
	- To publish a port 
		docker run -p <host_port>:<container_port> .....
		
	-P publish_all
		It binds all the exposed ports of the container to host machine port
		
	To map direct IP address to the host 
		port to port 
			ip:<host_port>:<container_port>
			ip::<container_port>
			
	Range of ports 
		many to one 
			-p 8080-8090:8080
		many to many 
			-p 8080-8085:8086-8091
			 - The total number of host ports in range should be same as the 
			   total number of container ports range.
				
Docker network types 
	1. Bridge 
		- This is a private internal network created by docker on the host machine 
		  by name docker0	
		- This is the default network type for all the container which are created 
          without any network configurations.
		- By default all the containers in the same bridge can communicate with 
		  eachother without any extra configuration.	
		- We cannot use container name for communication only IP address is allowed in 
		  default bridge.

		Custom bridge 
			To create bridge network 
				docker network create --driver bridge my_bride 
			
			- In custom bridge containers can communicate with eachother with container 
			  name and also with IP address.
			
	2. Host 		  
		- This driver removes the network isolation between docker and the host.
		- The containers are directly connected to host machine network without  
		  extra layer of any docker network.
		- Shares the same TCP.IP stack and same namespace of host machine.  
		- All the network interfaces which are there in host machine are 
		  accessable by this container.

	3. None 
		- Containers are not attached to any network by docker.
		- All the required network configurations need to be done 
		  manually.
		- The host or any other containers won't be able to communicate 
		  with this container untill a custom network is configured.
		  
ocker Architecture 
	Docker Daemon 
		- A background process that manages docker images, containers, network and volumes.
		- This Daemon constantly listens for docker API request and processes them.
	
	Docker REST API 
		- API which is used by applictions to interact with the docker daemon. 
		
	Docker CLI 
		- It is a command line interface for interacting with docker daemon through
		  REST api.
	
	Docker Objects 

Benifits of Docker 
	Flexible: 
		Complex applictions cab be divided and containerised in small compenets called 
		microservice. 
	
	Lightweight: 
		Containers share the machine’s OS system kernel and therefore do not require 
		an OS per application, driving higher server efficiencies and reducing server and licensing costs

	portable: 
		we can build images anywhere and then deploy to cloud, run anywhere.	

States of conatiner / Lifecycle of container 
	1. Created - if container is newly created and container is not yet started.
	2. Running - A currently running container. It means there is no problem 
				 with container to run the process.
	3. Exited - A container ran and completed ot executiom with failure.
	4. paused - A container whose process have been paused. (we can unpause the container)
	5. Dead - if docker daemon tried and failed to stop a container (host ram full)
	6. Restarting - container will be in the phase of retarting the main process.

Multistage build 
	How to optimize docker build process ?
	How to reduce the size of the docker image or cotainer ? 

	After docker 1.6 version docker released this option.
	1. There are 2 problems with the normal build process 
			1. Size: challenge is to keep the image and its containers size as minimal as possible.
			2. larger the surface area more the application is vurnalable to attacks. 
	
		- Multistage build allows us to define multiple FROM in same Dockerfile.
		- Dependency between multile FROM is maintained by naming FROM using 
		  AS keyword and we can refer this name in another FROM.

				FROM <base_image> AS <STAGE_NAME>
				
		- Only the final FROM image is created leaving back all the other FROM.
		- Copy only the required files from the named FROM stage like below.
				FROM final_build
				COPY --from <STAGE_NAME> <src_named_stage> <dest>
	
	2. Always try to use the slim / alpine / stretch version of base image instead 
	   od using the fully loaded base image.
	   
	exapmle: https://github.com/jaintpharsha/docker_multi_build.git		  
	
docker-compose 
	Installation 
		1. sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
		2. sudo chmod +x /usr/local/bin/docker-compose
		3. sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
		
	- docker-compose is a tool for defining and running multile container docker application with 
	  a single command.
	- We use YAML file to do docker related configurations then with a single command 
	  we can execute this YAML file to create docker objects defined in this file.	
	  
	docker-compose.yml 
		version: "3.8"
		services:
			jenkins:
				image: jenkins/jenkins:lts
				container_name: dc-jenkins
				ports:
					- "8080:8080"
					- "5000:5000"
				networks:
					- my_brid
			alpine:
				build: .
				container_name: dc-ubuntu
				volumes:
					- my_vol:/home
				networks:
					- my_brid
		networks:
			my_brid:
				driver: bridge

		volumes:
			my_vol: {} 
	